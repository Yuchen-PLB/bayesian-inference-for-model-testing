---
title: "STA 145"
author: "Yuchen Liu,"
date: "2023-06-14"
output: html_document
---

Q1) Example: Midge Wing Length

In this example, we have data on the wing length of nine members of a species of midge, which are small, two-winged flies. The observations, in increasing order, are as follows: (1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08). We want to make inferences about the population mean (θ) and variance (σ^2) based on these measurements.

Let's consider two different cases for data analysis:

Case 1: Prior information suggests that E(σ^2_0) = 0.01. In this case, we can specify the joint prior distribution as follows:

p(θ, σ^2) = p(θ) p(σ^2) = N(θ, μ_0, τ^2_0) × p(σ^2); σ^2 ~ gamma(ν_0/2, (ν_0/2)σ^2_0),

where μ_0 = 1.9 represents the typical wing length based on studies from other populations. Since wing lengths must be positive (θ > 0), we choose τ_0 = 0.95 to approximate the restriction that the prior distribution for θ has mass only on positive values. This choice ensures that most of the probability lies within two standard deviations of the mean, considering μ_0 - 2 × τ_0 > 0.

Case 2: Alternatively, instead of using the prior information on σ^2_0, we can employ a more flexible prior specified as:

p(θ, σ^2, σ^2_0, β) = p(θ) p(σ^2|σ^2_0) p(σ^2_0|β) p(β)
= N(θ, μ_0, τ^2_0) × p(σ^2|σ^2_0) p(σ^2_0|β) p(β); σ^2 ~ gamma(ν_0/2, (ν_0/2)σ^2_0),

where β represents additional parameters for the prior distributions. This formulation allows for more flexibility by incorporating prior information on both σ^2 and σ^2_0.

These are the different options for data analysis that can be considered in this study.

## Case 1
Obtain the form of the full conditional distributions and write the Gibbs Sampler algorithm

* $p\left(\theta \mid \sigma^{2}, y_{1}, \ldots, y_{n}\right)$ given by  $\left\{\theta \mid \sigma^{2}, y_{1}, \ldots, y_{n}\right\} \sim \operatorname{normal}\left(\mu_{n}, \tau_{n}^{2}\right)$ with
$$\mu_{n}=\frac{\mu_{0} / \tau_{0}^{2}+n \bar{y} / \sigma^{2}}{1 / \tau_{0}^{2}+n / \sigma^{2}} \text { and } \tau_{n}^{2}=\left(\frac{1}{\tau_{0}^{2}}+\frac{n}{\sigma^{2}}\right)^{-1} .$$

* $\left\{\sigma^{2} \mid \theta, y_{1}, \ldots, y_{n}\right\} \sim$ inverse-gamma $\left(\nu_{n} / 2, \nu_{n} \sigma_{n}^{2}(\theta) / 2\right)$, where
$$\nu_{n}=\nu_{0}+n, \quad \sigma_{n}^{2}(\theta)=\frac{1}{\nu_{n}}\left[\nu_{0} \sigma_{0}^{2}+n s_{n}^{2}(\theta)\right]$$
and $s_{n}^{2}(\theta)=\sum\left(y_{i}-\theta\right)^{2} / n$


#### 1. Run a Gibbs sampler of at least 5,000 iterations and attach the R script.

```{r}
##data
mu0<-1.9  ; k0<-1
s20<-.01 ; nu0<-1
t20<-0.95^2
## data
y<-c(1.64,1.70,1.72,1.74,1.82,1.82,1.82,1.90,2.08)
n<-length(y) ; mean.y <- ybar<-mean(y) ; var.y <- s2<-var(y)

## posterior inference
kn<-k0+n ; nun<-nu0+n
mun<- (k0*mu0 + n*ybar)/kn  
s2n<- (nu0*s20 +(n-1)*s2 +k0*n*(ybar-mu0)^2/(kn))/(nun)
mun
s2n
MLE_1 <- ybar

## MLE 2

MLE_2 <- s2


## MLE 2

MLE_3 <- 1/s2

dinvgamma<-function(x,a,b) {
ld<- a*log(b) -lgamma(a) -(a+1)*log(x)  -b/x 
exp(ld)
                            }

gs<-100
theta<-seq(1.6,2.0,length=gs)
is2<-seq(15,160 ,length=gs)
s2g<-seq(.001,.045,length=gs)

ld.th.is2<-ld.th.s2<-matrix(0,gs,gs)
for(i in 1:gs) { for(j in 1:gs) {
    ld.th.is2[i,j]<- dnorm(theta[i],mun,1/sqrt( is2[j] *10) ,log=TRUE) +
                   dgamma(is2[j],10/2,10*s2n/2, log=TRUE )
    ld.th.s2[i,j]<- dnorm(theta[i],mun,sqrt(s2g[j]/10) ,log=TRUE) +
                    log( dinvgamma(s2g[j],10/2,10*s2n/2 ))
                     }} 

```

```{r}
set.seed(1)
S<-5000 # Number of samples
PHI<-matrix(nrow=S,ncol=2)
PHI[1,]<-phi<-c( mean.y, 1/var.y)

## Gibbs sampling algorithm
for(s in 2:S) {

# generate a new theta value from its full conditional
mun<-  ( mu0/t20 + n*mean.y*phi[2] ) / ( 1/t20 + n*phi[2] )
t2n<- 1/( 1/t20 + n*phi[2] )
phi[1]<-rnorm(1, mun, sqrt(t2n) )

# generate a new sigma^2 value from its full conditional
nun<- nu0+n
s2n<- (nu0*s20 + (n-1)*var.y + n*(mean.y-phi[1])^2 ) /nun
phi[2]<- rgamma(1, nun/2, nun*s2n/2)

PHI[s,]<-phi         



                }   

par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
m1<-5
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-15
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-100
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )
                
              
PHI2<-PHI   
```
#### 2. Using posterior quantities (e.g., plots, quantiles, means, medians, posterior probabilities) describe the marginal and joint posterior distributions (including in Case 2 the marginal posterior distribution of σ2 0 and β). (10 points)

```{r warning=FALSE,echo = FALSE}

## Discrete approximations: a plot of the posterior
G<-100 ; H<-100

mean.grid<-seq(1.505,2.00,length=G) 
prec.grid<-seq(1.75,175,length=H) 

post.grid<-matrix(nrow=G,ncol=H)

for(g in 1:G) {
  for(h in 1:H) { 
    
    post.grid[g,h]<- dnorm(mean.grid[g], mu0, sqrt(t20)) *
                     dgamma(prec.grid[h], nu0/2, s20*nu0/2 ) *
                     prod( dnorm(y,mean.grid[g],1/sqrt(prec.grid[h])) )
                  }
                }

post.grid<-post.grid/sum(post.grid)

par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
image( mean.grid,prec.grid,post.grid,col=gray( (10:0)/10 ),
     xlab=expression(theta), ylab=expression(tilde(sigma)^2) )

mean.post<- apply(post.grid,1,sum)
plot(mean.grid,mean.post,type="l",xlab=expression(theta),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))

prec.post<-apply(post.grid,2,sum)
plot(prec.grid,prec.post,type="l",xlab=expression(tilde(sigma)^2),
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 

```

```{r}

## posterior marginal density
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000




plot(density(PHI2[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI2[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI2[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI2[,2],prob=c(.025,.975)),lwd=2,col="gray")

abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI2[,2])


```


```{r}
## joint marginal 
par(mfrow=c(1,2),mar=c(2.75,2.75,2.75,2.75),mgp=c(1.70,.70,0))
sseq<-1:1000

image( mean.grid,prec.grid,post.grid,
     xlab=expression(theta), ylab=expression(tilde(sigma)^2) ,
     xlim=range(PHI2[,1]),ylim=range(PHI2[,2]), main="Gibbs Sampling - sigma^2_0=0.01")
points(PHI2[sseq,1],PHI2[sseq,2],pch=".",cex=1.25 )
abline(v=MLE_1,lwd=2,lty=2,col=2)
abline(h=MLE_3,lwd=2,lty=2,col=2)


```

```{r}
quantile(PHI2[,1],prob=c(.025,.975))
quantile(PHI2[,2],prob=c(.025,.975))
summary(PHI2)
apply(PHI2,2,sd) 


```

#### 4. Implement the MCMC diagnostics. (10 points)

```{r}
set.seed(1)
S<-5000

s2.postsample<-1/rgamma(S,  (nu0+n)/2, s2n*(nu0+n)/2 )

theta.postsample<-rnorm(S, mun, sqrt(s2.postsample/(k0+n)))


quantile(theta.postsample, c(.025,.975))

##
layout(matrix(c(1,1,2,3),2,2,byrow=T))
par(mar=c(3,3,1,1),mgp=c(1.75,.75,0))
image(theta,s2g,exp(ld.th.s2),xlab=expression(theta),
       ylab=expression(sigma^2),xlim=c(1.60,2.0),ylim=c(.001,.07) )
points(theta.postsample[1:5000], s2.postsample[1:5000],pch=".",
   xlab=expression(theta),ylab=expression(sigma^2),xlim=c(1.65,1.95),
   ylim=c(.005,.07) )
plot(density(s2.postsample,adjust=3),main="",xlab=expression(sigma^2), 
     xlim=c(0,.075),ylab=expression( paste(italic("p("),
     sigma^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
plot(density(theta.postsample,adjust=3),main="",xlab=expression(theta),
     xlim=c(1.60,2.0),ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
quantile( theta.postsample,c(.025,.975))
abline(v=quantile( theta.postsample,c(.025,.975)),col="gray",lwd=2)

## t-test based confidence interval
n<-length(y) ; ybar<-mean(y) ; s2<-var(y)

ybar+qt( c(.025,.975), n-1) *sqrt(s2/n)

abline( v= ybar+qt( c(.025,.975), n-1) *sqrt(s2/n), col="black",lwd=2)
```



```{r}
library(dlm)
library(dlm)
par(mfrow=c(3,2))

# Autocorrelation function

acf(PHI2[,1],main="Case 1", xlab=expression(theta))
acf(PHI2[,2],main="Case 1", xlab=expression(tilde(sigma)^2))

# Ergodic mean

plot(ergMean(PHI2[,1]),main="Case 1", ylab=expression(theta),xlab="MCMC Samples",type="l")
plot(ergMean(PHI2[,2]),main="Case 1", ylab=expression(tilde(sigma)^2),xlab="MCMC Samples",type="l")

# Mixing

plot(PHI2[,1],main="Case 1", ylab=expression(theta),xlab="MCMC Samples",type="l")
plot(PHI2[,2],main="Case 1", ylab=expression(tilde(sigma)^2),xlab="MCMC Samples",type="l")


```

see appendix for more

## Case2 


basic case  a1 = 1
#### 1. Run a Gibbs sampler of at least 5,000 iterations and attach the R script.

```{r}
a = 1
a1 = 1
b = 100
set.seed(1)
S<-5000 # Number of samples
a<-1
b<-100

PHI<-matrix(nrow=S,ncol=3) # New change ncol=2 by ncol=3
PHI[1,]<-phi<-c( mean.y, 1/var.y, 0.01) # New: Include a new starting point 

## Gibbs sampling algorithm

for(s in 2:S) {
	


# generate a new theta value from its full conditional

mun<-  ( mu0/t20 + n*mean.y*phi[2] ) / ( 1/t20 + n*phi[2] )
t2n<- 1/( 1/t20 + n*phi[2] )
phi[1]<-rnorm(1, mun, sqrt(t2n) )

# generate a new sigma^2 value from its full conditional
nun<- nu0+n
s2n<- (nu0*s20 + (n-1)*var.y + n*(mean.y-phi[1])^2 ) /nun
phi[2]<- rgamma(1, nun/2, nun*s2n/2)
beta <- rgamma(1, a, b)
phi[3] <-  rgamma(1, shape=a1 + nu0/2, rate= beta + (nu0/2)*phi[2])

PHI[s,]<-phi         

                }   

par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
m1<-5
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-15
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-100
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )
                
                
                
PHI3<-PHI
```

```{r}
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000


plot(density(PHI3[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI3[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI3[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI3[,2],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI3[,3],adj=2), xlab=expression(sigma[0]^2),main="",
     ylab=expression( paste(italic("p("),
    sigma[0]^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI3[,3],prob=c(.025,.975)),lwd=2,col="gray")
abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI3[,3])

```

```{r}
## posterior marginal density
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000




plot(density(PHI3[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI2[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI3[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI3[,2],prob=c(.025,.975)),lwd=2,col="gray")

abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI3[,2])
```

```{r}
## joint marginal 
par(mfrow=c(1,2),mar=c(2.75,2.75,2.75,2.75),mgp=c(1.70,.70,0))
sseq<-1:1000

image( mean.grid,prec.grid,post.grid,
     xlab=expression(theta), ylab=expression(tilde(sigma)^2) ,
     xlim=range(PHI3[,1]),ylim=range(PHI3[,2]), main="Gibbs Sampling - sigma^2_0=0.01")
points(PHI3[sseq,1],PHI3[sseq,2],pch=".",cex=1.25 )
abline(v=MLE_1,lwd=2,lty=2,col=2)
abline(h=MLE_3,lwd=2,lty=2,col=2)

```

#### Case2 with a2 = 114514

```{r}
a = 1
a2 = 114514
b = 100
set.seed(1)
S<-5000 # Number of samples
a<-1
b<-100

PHI<-matrix(nrow=S,ncol=3) # New change ncol=2 by ncol=3
PHI[1,]<-phi<-c( mean.y, 1/var.y, 0.01) # New: Include a new starting point 

## Gibbs sampling algorithm

for(s in 2:S) {
	


# generate a new theta value from its full conditional

mun<-  ( mu0/t20 + n*mean.y*phi[2] ) / ( 1/t20 + n*phi[2] )
t2n<- 1/( 1/t20 + n*phi[2] )
phi[1]<-rnorm(1, mun, sqrt(t2n) )

# generate a new sigma^2 value from its full conditional
nun<- nu0+n
s2n<- (nu0*s20 + (n-1)*var.y + n*(mean.y-phi[1])^2 ) /nun
phi[2]<- rgamma(1, nun/2, nun*s2n/2)
beta <- rgamma(1, a, b)
phi[3] <-  rgamma(1, shape=a2 + nu0/2, rate= beta + (nu0/2)*phi[2])

PHI[s,]<-phi         



                }   

par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
m1<-5
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-15
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-100
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )
                
                
                
PHI4<-PHI

```


```{r}
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000



plot(density(PHI4[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI4[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI4[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI4[,2],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI4[,3],adj=2), xlab=expression(sigma[0]^2),main="",
     ylab=expression( paste(italic("p("),
    sigma[0]^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI4[,3],prob=c(.025,.975)),lwd=2,col="gray")
abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI4[,3])





```

```{r}
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000




plot(density(PHI4[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI4[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI4[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI4[,2],prob=c(.025,.975)),lwd=2,col="gray")

abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI4[,2])

```

```{r}
## joint marginal 
par(mfrow=c(1,2),mar=c(2.75,2.75,2.75,2.75),mgp=c(1.70,.70,0))
sseq<-1:1000

image( mean.grid,prec.grid,post.grid,
     xlab=expression(theta), ylab=expression(tilde(sigma)^2) ,
     xlim=range(PHI4[,1]),ylim=range(PHI4[,2]), main="Gibbs Sampling - sigma^2_0=0.01")
points(PHI4[sseq,1],PHI4[sseq,2],pch=".",cex=1.25 )
abline(v=MLE_1,lwd=2,lty=2,col=2)
abline(h=MLE_3,lwd=2,lty=2,col=2)

```

#### Case2 with a3 = 1145141919810

```{r}

a3 = 1145141919810
set.seed(1)
S<-5000 # Number of samples
a<-1
b<-100

PHI<-matrix(nrow=S,ncol=3) # New change ncol=2 by ncol=3
PHI[1,]<-phi<-c( mean.y, 1/var.y, 0.01) # New: Include a new starting point 

## Gibbs sampling algorithm

for(s in 2:S) {
	


# generate a new theta value from its full conditional

mun<-  ( mu0/t20 + n*mean.y*phi[2] ) / ( 1/t20 + n*phi[2] )
t2n<- 1/( 1/t20 + n*phi[2] )
phi[1]<-rnorm(1, mun, sqrt(t2n) )

# generate a new sigma^2 value from its full conditional
nun<- nu0+n
s2n<- (nu0*s20 + (n-1)*var.y + n*(mean.y-phi[1])^2 ) /nun
phi[2]<- rgamma(1, nun/2, nun*s2n/2)
beta <- rgamma(1, a, b)
phi[3] <-  rgamma(1, shape=a3 + nu0/2, rate= beta + (nu0/2)*phi[2])

PHI[s,]<-phi         

                }   

par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
m1<-5
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-15
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )

m1<-100
plot( PHI[1:m1,],type="l",xlim=range(PHI[1:100,1]), ylim=range(PHI[1:100,2]),
       lty=1,col="gray",xlab=expression(theta),ylab=expression(tilde(sigma)^2))
text(  PHI[1:m1,1], PHI[1:m1,2], c(1:m1) )
                
PHI5<-PHI


```

```{r}
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000



plot(density(PHI5[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI5[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI5[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI5[,2],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI5[,3],adj=2), xlab=expression(sigma[0]^2),main="",
     ylab=expression( paste(italic("p("),
    sigma[0]^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI5[,3],prob=c(.025,.975)),lwd=2,col="gray")
abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI5[,3])



```

```{r}
par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
sseq<-1:1000




plot(density(PHI5[,1],adj=2),  xlab=expression(theta),main="",
     xlim=c(1.55,2.05),
 ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
abline(v=quantile(PHI5[,1],prob=c(.025,.975)),lwd=2,col="gray")

plot(density(PHI5[,2],adj=2), xlab=expression(tilde(sigma)^2),main="",
     ylab=expression( paste(italic("p("),
     tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
abline(v=quantile(PHI5[,2],prob=c(.025,.975)),lwd=2,col="gray")

abline(v=0.01,lwd=2,col="blue",lty=2)

hist(PHI5[,2])




```


```{r}
quantile(PHI3[,1],prob=c(.025,.975))
quantile(PHI3[,2],prob=c(.025,.975))
summary(PHI3)
apply(PHI3,2,sd) 


quantile(PHI4[,1],prob=c(.025,.975))
quantile(PHI4[,2],prob=c(.025,.975))
summary(PHI4)
apply(PHI4,2,sd) 


quantile(PHI5[,1],prob=c(.025,.975))
quantile(PHI5[,2],prob=c(.025,.975))
summary(PHI5)
apply(PHI5,2,sd) 
```

#### Describe the effects of the prior choice for σ20 and β in your results. Consider posterior quantities such as credible intervals, variances, means and include posterior marginal and joint densities. (40 points)
In this case the σ20 is the none informative prior of the distribution , so we compares some of the extreme case of the distribution for σ20, although it has great effect on the sigma0^~ has a little influence on the credible intervals, variances, means and include posterior marginal and joint densities

we observed that as the a1 we selected greatly increase, the confidence interval converage alittle bit , but as sigma0^~ become more disperse, the converaing effect decreased.

Appendix:
![Appendix proof for the Q1](C:/Users/THINKPAD x1/Desktop/Sta145(1)_page-0001.jpg)
MCMC for case two:

```{r}

set.seed(1)
S<-5000

s2.postsample<-1/rgamma(S,  (nu0+n)/2, s2n*(nu0+n)/2 )

theta.postsample<-rnorm(S, mun, sqrt(s2.postsample/(k0+n)))


quantile(theta.postsample, c(.025,.975))

##
layout(matrix(c(1,1,2,3),2,2,byrow=T))
par(mar=c(3,3,1,1),mgp=c(1.75,.75,0))
image(theta,s2g,exp(ld.th.s2),xlab=expression(theta),
       ylab=expression(sigma^2),xlim=c(1.60,2.0),ylim=c(.001,.07) )
points(theta.postsample[1:5000], s2.postsample[1:5000],pch=".",
   xlab=expression(theta),ylab=expression(sigma^2),xlim=c(1.65,1.95),
   ylim=c(.005,.07) )
plot(density(s2.postsample,adjust=3),main="",xlab=expression(sigma^2), 
     xlim=c(0,.075),ylab=expression( paste(italic("p("),
     sigma^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
plot(density(theta.postsample,adjust=3),main="",xlab=expression(theta),
     xlim=c(1.60,2.0),ylab=expression( paste(italic("p("),
     theta,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
quantile( theta.postsample,c(.025,.975))
abline(v=quantile( theta.postsample,c(.025,.975)),col="gray",lwd=2)

## t-test based confidence interval
n<-length(y) ; ybar<-mean(y) ; s2<-var(y)

ybar+qt( c(.025,.975), n-1) *sqrt(s2/n)

abline( v= ybar+qt( c(.025,.975), n-1) *sqrt(s2/n), col="black",lwd=2)
```


```{r}
par(mfrow=c(3,2))

# Autocorrelation function

acf(PHI4[,1],main="Case 1", xlab=expression(theta))
acf(PHI4[,2],main="Case 1", xlab=expression(tilde(sigma)^2))

# Ergodic mean

plot(ergMean(PHI4[,1]),main="Case 1", ylab=expression(theta),xlab="MCMC Samples",type="l")
plot(ergMean(PHI4[,2]),main="Case 1", ylab=expression(tilde(sigma)^2),xlab="MCMC Samples",type="l")

# Mixing

plot(PHI4[,1],main="Case 1", ylab=expression(theta),xlab="MCMC Samples",type="l")
plot(PHI4[,2],main="Case 1", ylab=expression(tilde(sigma)^2),xlab="MCMC Samples",type="l")


```

There should not be difference for MCMC between the case two, that is because the weak infomative prior has little to null contribution to the overall distribution and would not influence the answer by Monte Carlo method
